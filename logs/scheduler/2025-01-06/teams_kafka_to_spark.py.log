[2025-01-06T05:17:29.179+0000] {processor.py:157} INFO - Started process (PID=29) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:17:29.181+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:17:29.185+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:17:29.183+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:17:31.316+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:17:31.392+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:17:31.391+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:17:31.427+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:17:31.427+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:17:31.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 2.294 seconds
[2025-01-06T05:18:01.789+0000] {processor.py:157} INFO - Started process (PID=73) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:18:01.790+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:18:01.791+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:18:01.791+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:18:02.409+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:18:02.436+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:18:02.436+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:18:02.449+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:18:02.449+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:18:02.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.682 seconds
[2025-01-06T05:18:33.461+0000] {processor.py:157} INFO - Started process (PID=114) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:18:33.462+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:18:33.463+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:18:33.463+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:18:34.014+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:18:34.036+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:18:34.035+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:18:34.050+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:18:34.050+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:18:34.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.618 seconds
[2025-01-06T05:19:04.766+0000] {processor.py:157} INFO - Started process (PID=155) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:19:04.769+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:19:04.771+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:19:04.770+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:19:05.785+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:19:05.829+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:19:05.828+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:19:05.867+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:19:05.867+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:19:05.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 1.155 seconds
[2025-01-06T05:19:36.789+0000] {processor.py:157} INFO - Started process (PID=196) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:19:36.791+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:19:36.792+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:19:36.792+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:19:37.307+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:19:37.327+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:19:37.327+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:19:37.343+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:19:37.343+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:19:37.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.573 seconds
[2025-01-06T05:20:08.390+0000] {processor.py:157} INFO - Started process (PID=237) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:20:08.392+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:20:08.393+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:20:08.393+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:20:08.812+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:20:08.827+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:20:08.827+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:20:08.840+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:20:08.840+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:20:08.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.471 seconds
[2025-01-06T05:20:39.856+0000] {processor.py:157} INFO - Started process (PID=278) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:20:39.858+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:20:39.860+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:20:39.859+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:20:40.242+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:20:40.258+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:20:40.258+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:20:40.273+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:20:40.272+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:20:40.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.441 seconds
[2025-01-06T05:21:11.206+0000] {processor.py:157} INFO - Started process (PID=319) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:21:11.209+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:21:11.210+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:21:11.210+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:21:11.661+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:21:11.677+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:21:11.677+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:21:11.693+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:21:11.693+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:21:11.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.523 seconds
[2025-01-06T05:21:41.834+0000] {processor.py:157} INFO - Started process (PID=360) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:21:41.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:21:41.842+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:21:41.841+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:21:42.801+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:21:42.849+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:21:42.849+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:21:42.892+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:21:42.892+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:21:42.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 1.149 seconds
[2025-01-06T05:22:13.401+0000] {processor.py:157} INFO - Started process (PID=401) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:22:13.403+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:22:13.404+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:22:13.403+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:22:14.062+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:22:14.095+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:22:14.095+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:22:14.113+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:22:14.113+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:22:14.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.735 seconds
[2025-01-06T05:22:44.290+0000] {processor.py:157} INFO - Started process (PID=442) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:22:44.292+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:22:44.295+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:22:44.294+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:22:44.658+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:22:44.674+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:22:44.674+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:22:44.689+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:22:44.689+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:22:44.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.415 seconds
[2025-01-06T05:23:15.659+0000] {processor.py:157} INFO - Started process (PID=483) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:23:15.663+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:23:15.665+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:23:15.665+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:23:16.185+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:23:16.206+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:23:16.205+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:23:16.222+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:23:16.222+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:23:16.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.585 seconds
[2025-01-06T05:23:46.957+0000] {processor.py:157} INFO - Started process (PID=524) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:23:46.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:23:46.960+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:23:46.959+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:23:47.404+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:23:47.421+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:23:47.421+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:23:47.437+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:23:47.436+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:23:47.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.502 seconds
[2025-01-06T05:24:17.556+0000] {processor.py:157} INFO - Started process (PID=565) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:24:17.560+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:24:17.562+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:24:17.561+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:24:17.965+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:24:17.986+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:24:17.986+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:24:18.003+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:24:18.003+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:24:18.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.471 seconds
[2025-01-06T05:24:49.061+0000] {processor.py:157} INFO - Started process (PID=606) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:24:49.064+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:24:49.065+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:24:49.065+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:24:49.622+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:24:49.646+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:24:49.646+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:24:49.664+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:24:49.664+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:24:49.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.626 seconds
[2025-01-06T05:25:06.542+0000] {processor.py:157} INFO - Started process (PID=644) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:25:06.545+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:25:06.546+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:25:06.545+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:25:06.989+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:25:06.988+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/teams_kafka_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/teams_kafka_to_spark.py", line 45, in <module>
    spark_home="/opt/spark" # Add this line <---------------------
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_home': '/opt/spark'}
[2025-01-06T05:25:06.989+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:25:07.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.469 seconds
[2025-01-06T05:25:37.601+0000] {processor.py:157} INFO - Started process (PID=685) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:25:37.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:25:37.605+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:25:37.605+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:25:37.910+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:25:37.909+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/teams_kafka_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/teams_kafka_to_spark.py", line 45, in <module>
    spark_home="/opt/spark" # Add this line <---------------------
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_home': '/opt/spark'}
[2025-01-06T05:25:37.910+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:25:37.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.324 seconds
[2025-01-06T05:26:07.966+0000] {processor.py:157} INFO - Started process (PID=726) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:26:07.969+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:26:07.971+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:26:07.970+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:26:08.387+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:26:08.385+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/teams_kafka_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/teams_kafka_to_spark.py", line 45, in <module>
    spark_home="/opt/spark" # Add this line <---------------------
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_home': '/opt/spark'}
[2025-01-06T05:26:08.387+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:26:08.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.439 seconds
[2025-01-06T05:26:39.308+0000] {processor.py:157} INFO - Started process (PID=768) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:26:39.312+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:26:39.313+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:26:39.313+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:26:39.618+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:26:39.617+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/teams_kafka_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/teams_kafka_to_spark.py", line 45, in <module>
    spark_home="/opt/spark" # Add this line <---------------------
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_home': '/opt/spark'}
[2025-01-06T05:26:39.618+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:26:39.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.324 seconds
[2025-01-06T05:27:09.974+0000] {processor.py:157} INFO - Started process (PID=809) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:27:09.977+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:27:09.978+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:27:09.978+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:27:10.277+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:27:10.276+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/teams_kafka_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/teams_kafka_to_spark.py", line 45, in <module>
    spark_home="/opt/spark" # Add this line <---------------------
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_home': '/opt/spark'}
[2025-01-06T05:27:10.277+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:27:10.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.316 seconds
[2025-01-06T05:27:40.316+0000] {processor.py:157} INFO - Started process (PID=852) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:27:40.320+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:27:40.321+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:27:40.321+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:27:40.573+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:27:40.572+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/teams_kafka_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/teams_kafka_to_spark.py", line 45, in <module>
    spark_home="/opt/spark" # Add this line <---------------------
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_home': '/opt/spark'}
[2025-01-06T05:27:40.573+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:27:40.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.267 seconds
[2025-01-06T05:28:10.615+0000] {processor.py:157} INFO - Started process (PID=893) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:28:10.616+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:28:10.617+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:28:10.617+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:28:10.897+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:28:10.896+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/teams_kafka_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/teams_kafka_to_spark.py", line 45, in <module>
    spark_home="/opt/spark" # Add this line <---------------------
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_home': '/opt/spark'}
[2025-01-06T05:28:10.897+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:28:10.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.292 seconds
[2025-01-06T05:28:20.756+0000] {processor.py:157} INFO - Started process (PID=902) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:28:20.759+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:28:20.762+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:28:20.760+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:28:21.307+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:28:21.306+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/teams_kafka_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/teams_kafka_to_spark.py", line 45, in <module>
    spark_home="/opt/spark" # Add this line <---------------------
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_home': '/opt/spark'}
[2025-01-06T05:28:21.308+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:28:21.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.574 seconds
[2025-01-06T05:28:52.323+0000] {processor.py:157} INFO - Started process (PID=943) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:28:52.325+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:28:52.326+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:28:52.325+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:28:52.628+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:28:52.627+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/teams_kafka_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/teams_kafka_to_spark.py", line 45, in <module>
    spark_home="/opt/spark" # Add this line <---------------------
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_home': '/opt/spark'}
[2025-01-06T05:28:52.628+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:28:52.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.320 seconds
[2025-01-06T05:29:23.570+0000] {processor.py:157} INFO - Started process (PID=984) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:29:23.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:29:23.574+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:29:23.573+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:29:24.143+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:29:24.137+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/teams_kafka_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/teams_kafka_to_spark.py", line 45, in <module>
    spark_home="/opt/spark" # Add this line <---------------------
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_home': '/opt/spark'}
[2025-01-06T05:29:24.147+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:29:24.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.605 seconds
[2025-01-06T05:29:54.353+0000] {processor.py:157} INFO - Started process (PID=1025) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:29:54.356+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:29:54.356+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:29:54.356+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:29:54.917+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:29:54.915+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/teams_kafka_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/teams_kafka_to_spark.py", line 45, in <module>
    spark_home="/opt/spark" # Add this line <---------------------
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_home': '/opt/spark'}
[2025-01-06T05:29:54.918+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:29:54.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.586 seconds
[2025-01-06T05:30:25.071+0000] {processor.py:157} INFO - Started process (PID=1068) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:30:25.072+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:30:25.073+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:30:25.072+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:30:25.479+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:30:25.478+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/teams_kafka_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/teams_kafka_to_spark.py", line 45, in <module>
    spark_home="/opt/spark" # Add this line <---------------------
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_home': '/opt/spark'}
[2025-01-06T05:30:25.480+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:30:25.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.423 seconds
[2025-01-06T05:30:56.365+0000] {processor.py:157} INFO - Started process (PID=1109) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:30:56.369+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:30:56.370+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:30:56.369+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:30:56.692+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:30:56.691+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/teams_kafka_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/teams_kafka_to_spark.py", line 45, in <module>
    spark_home="/opt/spark" # Add this line <---------------------
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_home': '/opt/spark'}
[2025-01-06T05:30:56.692+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:30:56.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.345 seconds
[2025-01-06T05:31:26.747+0000] {processor.py:157} INFO - Started process (PID=1150) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:31:26.749+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:31:26.749+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:31:26.749+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:31:27.156+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:31:27.155+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/teams_kafka_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/teams_kafka_to_spark.py", line 45, in <module>
    spark_home="/opt/spark" # Add this line <---------------------
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_home': '/opt/spark'}
[2025-01-06T05:31:27.156+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:31:27.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.424 seconds
[2025-01-06T05:31:57.238+0000] {processor.py:157} INFO - Started process (PID=1191) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:31:57.240+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:31:57.241+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:31:57.241+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:31:57.527+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:31:57.526+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/teams_kafka_to_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/teams_kafka_to_spark.py", line 45, in <module>
    spark_home="/opt/spark" # Add this line <---------------------
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: submit_spark_job). Invalid arguments were:
**kwargs: {'spark_home': '/opt/spark'}
[2025-01-06T05:31:57.527+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:31:57.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.304 seconds
[2025-01-06T05:32:25.759+0000] {processor.py:157} INFO - Started process (PID=1230) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:32:25.762+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:32:25.764+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:32:25.764+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:32:26.190+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:32:26.252+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:32:26.252+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:32:26.264+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:32:26.264+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:32:26.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.520 seconds
[2025-01-06T05:32:56.561+0000] {processor.py:157} INFO - Started process (PID=1271) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:32:56.564+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:32:56.566+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:32:56.565+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:32:56.912+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:32:56.925+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:32:56.924+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:32:56.936+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:32:56.935+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:32:56.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.388 seconds
[2025-01-06T05:33:27.579+0000] {processor.py:157} INFO - Started process (PID=1312) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:33:27.580+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:33:27.581+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:33:27.581+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:33:28.158+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:33:28.171+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:33:28.171+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:33:28.183+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:33:28.183+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:33:28.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.621 seconds
[2025-01-06T05:33:58.348+0000] {processor.py:157} INFO - Started process (PID=1354) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:33:58.349+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:33:58.350+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:33:58.350+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:33:58.684+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:33:58.697+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:33:58.696+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:33:58.708+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:33:58.708+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:33:58.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.371 seconds
[2025-01-06T05:34:28.750+0000] {processor.py:157} INFO - Started process (PID=1396) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:34:28.750+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:34:28.751+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:34:28.751+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:34:29.006+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:34:29.019+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:34:29.019+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:34:29.029+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:34:29.029+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:34:29.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.290 seconds
[2025-01-06T05:34:59.074+0000] {processor.py:157} INFO - Started process (PID=1437) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:34:59.074+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:34:59.075+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:34:59.075+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:34:59.475+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:34:59.488+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:34:59.488+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:34:59.500+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:34:59.500+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:34:59.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.437 seconds
[2025-01-06T05:35:29.719+0000] {processor.py:157} INFO - Started process (PID=1476) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:35:29.722+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:35:29.724+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:35:29.724+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:35:30.288+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:35:30.302+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:35:30.302+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:35:30.313+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:35:30.313+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:35:30.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.608 seconds
[2025-01-06T05:36:00.402+0000] {processor.py:157} INFO - Started process (PID=1519) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:36:00.404+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:36:00.406+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:36:00.405+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:36:00.746+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:36:00.760+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:36:00.760+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:36:00.772+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:36:00.772+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:36:00.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.380 seconds
[2025-01-06T05:36:31.751+0000] {processor.py:157} INFO - Started process (PID=1560) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:36:31.755+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:36:31.756+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:36:31.755+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:36:32.024+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:36:32.037+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:36:32.037+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:36:32.049+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:36:32.048+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:36:32.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.311 seconds
[2025-01-06T05:37:03.037+0000] {processor.py:157} INFO - Started process (PID=1601) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:37:03.040+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:37:03.042+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:37:03.041+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:37:03.312+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:37:03.324+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:37:03.324+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:37:03.335+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:37:03.335+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:37:03.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.311 seconds
[2025-01-06T05:37:34.327+0000] {processor.py:157} INFO - Started process (PID=1642) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:37:34.328+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:37:34.329+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:37:34.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:37:34.587+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:37:34.599+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:37:34.599+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:37:34.610+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:37:34.610+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:37:34.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.300 seconds
[2025-01-06T05:38:05.009+0000] {processor.py:157} INFO - Started process (PID=1683) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:38:05.011+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:38:05.012+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:38:05.012+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:38:05.276+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:38:05.288+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:38:05.288+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:38:05.300+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:38:05.300+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:38:05.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.301 seconds
[2025-01-06T05:38:35.628+0000] {processor.py:157} INFO - Started process (PID=1724) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:38:35.631+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:38:35.632+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:38:35.631+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:38:35.945+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:38:35.958+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:38:35.958+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:38:35.969+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:38:35.969+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:38:35.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.355 seconds
[2025-01-06T05:39:03.909+0000] {processor.py:157} INFO - Started process (PID=1765) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:39:03.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:39:03.911+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:39:03.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:39:04.371+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:39:04.449+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:39:04.448+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:39:04.463+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:39:04.463+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:39:04.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.569 seconds
[2025-01-06T05:39:35.208+0000] {processor.py:157} INFO - Started process (PID=1806) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:39:35.210+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:39:35.211+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:39:35.211+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:39:35.671+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:39:35.686+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:39:35.686+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:39:35.698+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:39:35.698+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:39:35.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.504 seconds
[2025-01-06T05:40:06.078+0000] {processor.py:157} INFO - Started process (PID=1847) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:40:06.081+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:40:06.082+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:40:06.082+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:40:06.366+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:40:06.379+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:40:06.378+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:40:06.390+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:40:06.390+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:40:06.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.325 seconds
[2025-01-06T05:40:36.430+0000] {processor.py:157} INFO - Started process (PID=1888) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:40:36.431+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:40:36.431+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:40:36.431+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:40:36.759+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:40:36.772+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:40:36.772+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:40:36.784+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:40:36.783+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:40:36.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.364 seconds
[2025-01-06T05:41:06.864+0000] {processor.py:157} INFO - Started process (PID=1929) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:41:06.866+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:41:06.866+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:41:06.866+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:41:07.403+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:41:07.421+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:41:07.421+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:41:07.437+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:41:07.437+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:41:07.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.588 seconds
[2025-01-06T05:41:37.889+0000] {processor.py:157} INFO - Started process (PID=1968) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:41:37.892+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:41:37.894+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:41:37.893+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:41:38.416+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:41:38.431+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:41:38.430+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:41:38.442+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:41:38.442+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:41:38.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.572 seconds
[2025-01-06T05:42:09.421+0000] {processor.py:157} INFO - Started process (PID=2011) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:42:09.423+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:42:09.424+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:42:09.424+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:42:09.724+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:42:09.738+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:42:09.738+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:42:09.751+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:42:09.750+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:42:09.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.343 seconds
[2025-01-06T05:42:40.155+0000] {processor.py:157} INFO - Started process (PID=2052) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:42:40.156+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:42:40.157+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:42:40.157+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:42:40.492+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:42:40.509+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:42:40.509+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:42:40.523+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:42:40.523+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:42:40.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.381 seconds
[2025-01-06T05:43:10.571+0000] {processor.py:157} INFO - Started process (PID=2093) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:43:10.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:43:10.575+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:43:10.574+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:43:10.899+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:43:10.912+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:43:10.912+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:43:10.924+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:43:10.924+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:43:10.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.368 seconds
[2025-01-06T05:43:41.261+0000] {processor.py:157} INFO - Started process (PID=2134) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:43:41.262+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:43:41.263+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:43:41.263+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:43:41.628+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:43:41.642+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:43:41.642+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:43:41.654+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:43:41.654+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:43:41.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.405 seconds
[2025-01-06T05:44:11.922+0000] {processor.py:157} INFO - Started process (PID=2175) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:44:11.923+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:44:11.924+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:44:11.924+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:44:12.357+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:44:12.372+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:44:12.371+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:44:12.400+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:44:12.400+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:44:12.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.499 seconds
[2025-01-06T05:44:42.501+0000] {processor.py:157} INFO - Started process (PID=2216) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:44:42.504+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:44:42.505+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:44:42.505+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:44:42.849+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:44:42.863+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:44:42.862+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:44:42.875+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:44:42.875+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:44:42.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.386 seconds
[2025-01-06T05:45:13.109+0000] {processor.py:157} INFO - Started process (PID=2257) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:45:13.112+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:45:13.113+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:45:13.112+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:45:13.459+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:45:13.473+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:45:13.472+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:45:13.485+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:45:13.485+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:45:13.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.390 seconds
[2025-01-06T05:45:44.488+0000] {processor.py:157} INFO - Started process (PID=2298) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:45:44.492+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:45:44.494+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:45:44.493+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:45:44.772+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:45:44.784+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:45:44.784+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:45:44.795+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:45:44.795+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:45:44.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.320 seconds
[2025-01-06T05:46:14.891+0000] {processor.py:157} INFO - Started process (PID=2339) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:46:14.893+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:46:14.894+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:46:14.894+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:46:15.234+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:46:15.250+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:46:15.249+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:46:15.266+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:46:15.266+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:46:15.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.390 seconds
[2025-01-06T05:46:45.665+0000] {processor.py:157} INFO - Started process (PID=2380) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:46:45.667+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:46:45.669+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:46:45.668+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:46:45.952+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:46:45.964+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:46:45.964+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:46:45.976+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:46:45.976+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:46:45.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.326 seconds
[2025-01-06T05:47:16.127+0000] {processor.py:157} INFO - Started process (PID=2421) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:47:16.130+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:47:16.131+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:47:16.130+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:47:16.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:47:16.450+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:47:16.449+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:47:16.462+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:47:16.462+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:47:16.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.348 seconds
[2025-01-06T05:47:46.518+0000] {processor.py:157} INFO - Started process (PID=2462) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:47:46.519+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:47:46.520+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:47:46.520+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:47:46.786+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:47:46.798+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:47:46.798+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:47:46.809+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:47:46.809+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:47:46.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.303 seconds
[2025-01-06T05:48:17.193+0000] {processor.py:157} INFO - Started process (PID=2503) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:48:17.195+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:48:17.196+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:48:17.196+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:48:17.551+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:48:17.564+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:48:17.564+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:48:17.576+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:48:17.576+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:48:17.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.400 seconds
[2025-01-06T05:48:48.321+0000] {processor.py:157} INFO - Started process (PID=2544) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:48:48.323+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:48:48.324+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:48:48.323+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:48:48.602+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:48:48.614+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:48:48.614+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:48:48.626+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:48:48.626+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:48:48.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.319 seconds
[2025-01-06T05:49:19.128+0000] {processor.py:157} INFO - Started process (PID=2585) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:49:19.130+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:49:19.132+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:49:19.131+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:49:19.554+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:49:19.572+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:49:19.571+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:49:19.589+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:49:19.589+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:49:19.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.480 seconds
[2025-01-06T05:49:49.800+0000] {processor.py:157} INFO - Started process (PID=2626) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:49:49.802+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:49:49.803+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:49:49.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:49:50.078+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:49:50.092+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:49:50.091+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:49:50.103+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:49:50.103+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:49:50.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.317 seconds
[2025-01-06T05:50:20.286+0000] {processor.py:157} INFO - Started process (PID=2667) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:50:20.287+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:50:20.288+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:50:20.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:50:20.659+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:50:20.677+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:50:20.676+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:50:20.690+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:50:20.690+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:50:20.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.418 seconds
[2025-01-06T05:50:50.815+0000] {processor.py:157} INFO - Started process (PID=2708) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:50:50.817+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:50:50.818+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:50:50.818+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:50:51.104+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:50:51.117+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:50:51.117+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:50:51.129+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:50:51.129+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:50:51.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.332 seconds
[2025-01-06T05:51:21.225+0000] {processor.py:157} INFO - Started process (PID=2749) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:51:21.227+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:51:21.228+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:51:21.228+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:51:21.496+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:51:21.508+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:51:21.507+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:51:21.519+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:51:21.519+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:51:21.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.308 seconds
[2025-01-06T05:51:51.603+0000] {processor.py:157} INFO - Started process (PID=2790) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:51:51.605+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:51:51.606+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:51:51.606+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:51:51.873+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:51:51.886+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:51:51.886+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:51:51.897+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:51:51.897+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:51:51.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.307 seconds
[2025-01-06T05:52:21.964+0000] {processor.py:157} INFO - Started process (PID=2831) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:52:21.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:52:21.967+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:52:21.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:52:22.274+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:52:22.287+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:52:22.287+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:52:22.298+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:52:22.298+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:52:22.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.349 seconds
[2025-01-06T05:52:52.729+0000] {processor.py:157} INFO - Started process (PID=2872) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:52:52.730+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:52:52.731+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:52:52.731+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:52:52.996+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:52:53.009+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:52:53.009+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:52:53.021+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:52:53.020+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:52:53.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.303 seconds
[2025-01-06T05:53:23.218+0000] {processor.py:157} INFO - Started process (PID=2913) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:53:23.220+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:53:23.222+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:53:23.221+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:53:23.528+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:53:23.541+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:53:23.540+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:53:23.552+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:53:23.552+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:53:23.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.348 seconds
[2025-01-06T05:53:53.681+0000] {processor.py:157} INFO - Started process (PID=2954) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:53:53.683+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:53:53.684+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:53:53.684+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:53:53.960+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:53:53.974+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:53:53.974+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:53:53.986+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:53:53.986+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:53:53.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.318 seconds
[2025-01-06T05:54:24.042+0000] {processor.py:157} INFO - Started process (PID=2995) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:54:24.044+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:54:24.045+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:54:24.045+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:54:24.418+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:54:24.435+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:54:24.435+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:54:24.450+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:54:24.450+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:54:24.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.421 seconds
[2025-01-06T05:54:54.523+0000] {processor.py:157} INFO - Started process (PID=3036) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:54:54.527+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:54:54.528+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:54:54.528+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:54:54.799+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:54:54.812+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:54:54.811+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:54:54.823+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:54:54.823+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:54:54.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.319 seconds
[2025-01-06T05:55:24.934+0000] {processor.py:157} INFO - Started process (PID=3077) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:55:24.937+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:55:24.938+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:55:24.937+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:55:25.293+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:55:25.318+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:55:25.317+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:55:25.331+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:55:25.330+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:55:25.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.411 seconds
[2025-01-06T05:55:55.495+0000] {processor.py:157} INFO - Started process (PID=3118) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:55:55.496+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:55:55.496+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:55:55.496+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:55:55.754+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:55:55.767+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:55:55.766+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:55:55.778+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:55:55.778+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:55:55.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.293 seconds
[2025-01-06T05:56:26.061+0000] {processor.py:157} INFO - Started process (PID=3159) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:56:26.063+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:56:26.065+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:56:26.064+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:56:26.374+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:56:26.390+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:56:26.390+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:56:26.402+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:56:26.402+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:56:26.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.357 seconds
[2025-01-06T05:56:56.506+0000] {processor.py:157} INFO - Started process (PID=3200) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:56:56.508+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:56:56.508+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:56:56.508+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:56:56.836+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:56:56.852+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:56:56.852+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:56:56.863+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:56:56.863+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:56:56.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.368 seconds
[2025-01-06T05:57:26.933+0000] {processor.py:157} INFO - Started process (PID=3241) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:57:26.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:57:26.935+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:57:26.935+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:57:27.195+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:57:27.207+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:57:27.207+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:57:27.218+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:57:27.218+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:57:27.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.299 seconds
[2025-01-06T05:57:57.381+0000] {processor.py:157} INFO - Started process (PID=3282) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:57:57.382+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:57:57.382+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:57:57.382+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:57:57.820+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:57:57.842+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:57:57.842+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:57:57.858+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:57:57.857+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:57:57.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.489 seconds
[2025-01-06T05:58:28.002+0000] {processor.py:157} INFO - Started process (PID=3323) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:58:28.004+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:58:28.004+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:58:28.004+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:58:28.480+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:58:28.496+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:58:28.495+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:58:28.509+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:58:28.509+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:58:28.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.518 seconds
[2025-01-06T05:58:59.145+0000] {processor.py:157} INFO - Started process (PID=3360) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:58:59.148+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:58:59.149+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:58:59.149+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:58:59.621+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:58:59.637+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:58:59.637+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:58:59.649+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:58:59.649+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:58:59.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.528 seconds
[2025-01-06T05:59:29.992+0000] {processor.py:157} INFO - Started process (PID=3397) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:59:29.994+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T05:59:29.995+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:59:29.994+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:59:30.430+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T05:59:30.444+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:59:30.443+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T05:59:30.457+0000] {logging_mixin.py:150} INFO - [2025-01-06T05:59:30.457+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T05:59:30.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.479 seconds
[2025-01-06T06:00:00.907+0000] {processor.py:157} INFO - Started process (PID=3434) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:00:00.911+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T06:00:00.912+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:00:00.912+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:00:01.608+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:00:01.628+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:00:01.627+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T06:00:01.642+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:00:01.642+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T06:00:01.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.754 seconds
[2025-01-06T06:00:32.189+0000] {processor.py:157} INFO - Started process (PID=3471) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:00:32.192+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T06:00:32.194+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:00:32.194+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:00:32.643+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:00:32.661+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:00:32.660+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T06:00:32.676+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:00:32.676+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T06:00:32.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.505 seconds
[2025-01-06T06:01:03.164+0000] {processor.py:157} INFO - Started process (PID=3508) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:01:03.169+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T06:01:03.172+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:01:03.171+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:01:03.848+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:01:03.872+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:01:03.871+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T06:01:03.891+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:01:03.891+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T06:01:03.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.755 seconds
[2025-01-06T06:01:34.258+0000] {processor.py:157} INFO - Started process (PID=3545) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:01:34.263+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T06:01:34.264+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:01:34.263+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:01:34.848+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:01:34.869+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:01:34.869+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T06:01:34.884+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:01:34.884+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T06:01:34.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.646 seconds
[2025-01-06T06:02:05.670+0000] {processor.py:157} INFO - Started process (PID=3582) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:02:05.674+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T06:02:05.675+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:02:05.674+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:02:06.278+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:02:06.305+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:02:06.305+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T06:02:06.324+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:02:06.323+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T06:02:06.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.682 seconds
[2025-01-06T06:02:37.178+0000] {processor.py:157} INFO - Started process (PID=3619) to work on /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:02:37.181+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/teams_kafka_to_spark.py for tasks to queue
[2025-01-06T06:02:37.184+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:02:37.184+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:02:37.816+0000] {processor.py:836} INFO - DAG(s) dict_keys(['spark_kafka_to_postgres_dag']) retrieved from /opt/airflow/dags/teams_kafka_to_spark.py
[2025-01-06T06:02:37.843+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:02:37.842+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2025-01-06T06:02:37.860+0000] {logging_mixin.py:150} INFO - [2025-01-06T06:02:37.860+0000] {dag.py:3508} INFO - Setting next_dagrun for spark_kafka_to_postgres_dag to None, run_after=None
[2025-01-06T06:02:37.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/teams_kafka_to_spark.py took 0.715 seconds
